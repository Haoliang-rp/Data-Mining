{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = open('t1.txt', 'r').read()\n",
    "text2 = open('t2.txt', 'r').read()\n",
    "text3 = open('ca1851-match.txt', 'rb').read()\n",
    "text4 = open('ny1850-match.txt', 'rb').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = [text1, text2, text3, text4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A CSV file (Comma Separated Values File) is Kobe James by spreadsheet programs such as Microsoft Excel or OpenOffice Calc. If I want you to test download of a file which contains plain text data sets separated by commas\n",
      "(database) just ddownload this file. I am on this way that.\n"
     ]
    }
   ],
   "source": [
    "print(do[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shingling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Shingles():\n",
    "    def __init__(self, documents, k):\n",
    "        \"\"\"\n",
    "        documents: the input documents\n",
    "        k: number of shingles\n",
    "        \"\"\"\n",
    "        self.documents = documents\n",
    "    \n",
    "        self._k_shingle_ = [\n",
    "            [\n",
    "                d[i:i+k] for i in range(len(d) - k + 1)\n",
    "            ] for d in documents\n",
    "        ]\n",
    "        \n",
    "        res = set()\n",
    "        for d in self._k_shingle_:\n",
    "            res.update(set(d))\n",
    "        self.dict_ = {}\n",
    "        for k, v in enumerate(res):\n",
    "            self.dict_[v] = k  \n",
    "    \n",
    "    def get_hash_shingle(self):\n",
    "        return [sorted([self.dict_[x] for x in set(sh)]) for sh in self._k_shingle_]\n",
    "    \n",
    "    def compare_sets(self, s1, s2):\n",
    "        # computes the Jaccard similarity of two sets of integers\n",
    "        s1 = set(s1)\n",
    "        s2 = set(s2)\n",
    "        return len(s1.intersection(s2))/len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shingle_documents = K_Shingles(do, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashed_shingle = shingle_documents.get_hash_shingle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7412587412587412\n"
     ]
    }
   ],
   "source": [
    "ja = shingle_documents.compare_sets(hashed_shingle[0], hashed_shingle[1])\n",
    "print(ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5007718431614696\n"
     ]
    }
   ],
   "source": [
    "ja34 = shingle_documents.compare_sets(hashed_shingle[2], hashed_shingle[3])\n",
    "print(ja34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinHashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinHashing():\n",
    "    def __init__(self, func_num, num_shingle, random_generate=True, hash_functions=None):\n",
    "        '''\n",
    "        func_num: number of hash functions\n",
    "        num_shingle: total number of all shingles\n",
    "        random_generate: if False, the hash_functions will be the pre-defined ones\n",
    "        hash_functions: '(ax+b)%c'\n",
    "        '''\n",
    "        self.func_num = func_num\n",
    "        self.num_shingle = num_shingle\n",
    "        self.functions_params = []\n",
    "        \n",
    "        if not random_generate:\n",
    "            assert hash_functions is not None\n",
    "            assert self.func_num == len(hash_functions)\n",
    "            for hash_function in hash_functions:\n",
    "                remain = hash_function.split('%')[0]\n",
    "                c = int(hash_function.split('%')[1])\n",
    "                a = remain.split('+')[0][1:-1]\n",
    "                a = int(a) if a else 1\n",
    "                b = int(remain.split('+')[1][0:-1])\n",
    "                self.functions_params.append((a, b, c))\n",
    "        else:\n",
    "            for _ in range(func_num):\n",
    "                c = self.num_shingle + random.randint(0, 5)\n",
    "                self.functions_params.append((random.randint(1, c - 1), random.randint(1, c - 1), c))\n",
    "    \n",
    "    def min_hashing(self, labeled_shingles):\n",
    "        signatures = []\n",
    "        for shingle in labeled_shingles:\n",
    "            row = []\n",
    "            for i in range(self.func_num):\n",
    "                #ic(min([(self.functions_params[i][0] * x + self.functions_params[i][1]) % self.functions_params[i][2] for x in shingle]))\n",
    "                row.append(min([(self.functions_params[i][0] * x + self.functions_params[i][1]) % self.functions_params[i][2] for x in shingle]))\n",
    "            #ic(row)\n",
    "            signatures.append(row)\n",
    "        return signatures\n",
    "    \n",
    "    def compare_signatures(self, s1, s2):\n",
    "        # computes the Jaccard similarity of two sets of integers\n",
    "        same_c = 0\n",
    "        for i in range(len(s1)):\n",
    "            if s1[i] == s2[i]:\n",
    "                same_c += 1\n",
    "        return same_c/len(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = ['(x+1)%5', '(3x+1)%5', '(4x+11)%3']\n",
    "func_num = 1500\n",
    "num_shingle = len(shingle_documents.dict_)\n",
    "random_generate = True\n",
    "k = MinHashing(func_num, num_shingle, random_generate, functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k.functions_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = k.min_hashing(hashed_shingle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarites = k.compare_signatures(signatures[2], signatures[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSH():\n",
    "    def __init__(self, t, func_num, mode, signatures):\n",
    "        '''\n",
    "        t: similarity threshold\n",
    "        n / func_num: number of functions used in minhashing\n",
    "        mode: chose to avoid false negatives or false positives\n",
    "        '''\n",
    "        self.t = t\n",
    "        self.n = func_num\n",
    "        self.mode = mode\n",
    "        self.signatures = np.array(signatures)\n",
    "        \n",
    "        self.b, self.r = self.chose_b_r()\n",
    "\n",
    "    def chose_b_r(self):\n",
    "        # use binary search to find b accorfing to t and search mode\n",
    "        t = self.t\n",
    "        n = self.n\n",
    "        left = 1\n",
    "        right = n\n",
    "        middle = int((right - left) / 2)\n",
    "        \n",
    "        r = int(n / middle)\n",
    "        similarity = (1/middle)**(1/r)\n",
    "            \n",
    "        if self.mode == 'false_negatives':\n",
    "            while similarity > t or similarity < t - 0.05:\n",
    "                if similarity < t - 0.005:\n",
    "                    right = middle\n",
    "                    middle = left + int((middle - left)/2)\n",
    "                    r = int(n / middle)\n",
    "                    similarity = (1/middle)**(1/r)\n",
    "                else:\n",
    "                    left = middle\n",
    "                    middle = int(middle + (right - middle) / 2)\n",
    "                    r = int(n / middle)\n",
    "                    similarity = (1/middle)**(1/r)\n",
    "        else:\n",
    "            while similarity > t + 0.05 or similarity < t:\n",
    "                if similarity < t:\n",
    "                    right = middle\n",
    "                    middle = left + int((middle - left)/2)\n",
    "                    r = int(n / middle)\n",
    "                    similarity = (1/middle)**(1/r)\n",
    "                else:\n",
    "                    left = middle\n",
    "                    middle = int(middle + (right - middle) / 2)\n",
    "                    r = int(n / middle)\n",
    "                    similarity = (1/middle)**(1/r)\n",
    "        return middle, r\n",
    "    \n",
    "    def find_candidate_pairs(self):\n",
    "        candidate_dict = defaultdict(set)\n",
    "        num_doc = self.signatures.shape[0]\n",
    "        \n",
    "        def create_dict(sig_part):\n",
    "            for j in range(num_doc):\n",
    "                for k in range(j+1, num_doc):\n",
    "                    if k not in candidate_dict[(j)] and all(sig_part[j] == sig_part[k]):\n",
    "                        candidate_dict[(j)].add(k)\n",
    "                        candidate_dict[(k)].add(j)\n",
    "        \n",
    "        for i in range(self.b):\n",
    "            sig_part = self.signatures[:, i:i+self.r]\n",
    "            create_dict(sig_part)\n",
    "        \n",
    "        if self.b * self.r < self.n:\n",
    "            sig_part = self.signatures[:, self.b * self.r:]\n",
    "            create_dict(sig_part)\n",
    "        \n",
    "        return candidate_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = 'false_positives' # 'false_negatives'\n",
    "lsh = LSH(0.5, 1500, mode, signatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_dict = lsh.find_candidate_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set, {0: {1}, 1: {0}, 2: {3}, 3: {2}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.84 Safari/537.36\"\n",
    "headers = {'User-Agent':user_agent}\n",
    "def craw(url):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser', from_encoding='utf-8')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = open('t1.txt', 'r').read()\n",
    "text2 = open('t2.txt', 'r').read()\n",
    "text3 = open('ca1851-match.txt', 'r').read()\n",
    "text4 = open('ny1850-match.txt', 'r').read()\n",
    "text5  = str(craw(\"https://en.wikipedia.org/wiki/Boston_Celtics\"))\n",
    "text6 = str(craw('https://en.wikipedia.org/wiki/Los_Angeles_Lakers'))\n",
    "text7 = open('ca1851-nomatch.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "do = [text1, text2, text3, text4, text5, text6, text7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {0: {1}, 1: {0}, 2: {3}, 3: {2}, 4: {5}, 5: {4}})\n"
     ]
    }
   ],
   "source": [
    "NUM_SHINGLES = 5\n",
    "FUNC_NUM = 1000\n",
    "THRESHOLD = 0.4\n",
    "\n",
    "time_begin = time.time()\n",
    "\n",
    "shingle_documents = K_Shingles(do, NUM_SHINGLES)\n",
    "hashed_shingle = shingle_documents.get_hash_shingle()\n",
    "\n",
    "num_shingle = len(shingle_documents.dict_)\n",
    "random_generate = True\n",
    "min_hashing = MinHashing(FUNC_NUM, num_shingle, random_generate)\n",
    "signatures = min_hashing.min_hashing(hashed_shingle)\n",
    "\n",
    "mode = 'false_negatives' # 'false_positives'\n",
    "lsh = LSH(THRESHOLD, FUNC_NUM, mode, signatures)\n",
    "candidate_dict = lsh.find_candidate_pairs()\n",
    "\n",
    "similar_doc = defaultdict(set)\n",
    "for k, v in candidate_dict.items():\n",
    "    for candidate in v:\n",
    "        if candidate in similar_doc[k]: continue\n",
    "        \n",
    "        similarites = min_hashing.compare_signatures(signatures[k], signatures[candidate])\n",
    "#         print(similarites)\n",
    "        if similarites > THRESHOLD:\n",
    "            similar_doc[k].add(candidate)\n",
    "            similar_doc[candidate].add(k)\n",
    "print(similar_doc)\n",
    "\n",
    "time_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.218701975686209\n"
     ]
    }
   ],
   "source": [
    "scalability = (time_end - time_begin) / len(do)\n",
    "print(scalability)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
